# Deep-Learning-Semester-Project-
Sarcasm Detection on news headlines and Text generation on irish song lyrics
## Part a (Sentiment Analysis in Sarcasm Headline Dataset)
Dataset :https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json

### Explanation:

The project involves building a machine learning model for sarcasm detection using a sarcasm news dataset. The process includes data preprocessing, feature extraction, model selection, and evaluation. The chosen model is a Bidirectional LSTM, supported by a literature review and experimentation. The project also explores sentiment analysis using TextBlob, visualizations such as word clouds and bar charts, and the use of K-Fold cross-validation for model evaluation. The final model is tested on a separate dataset, and its performance is analyzed in terms of accuracy, precision, recall, and F1-score. Additionally, the project includes the development of a user interface for detecting sarcasm in random user-input text. The use of various Python libraries and tools, such as TensorFlow, NumPy, Matplotlib, and NLTK, is highlighted throughout the explanation. The results demonstrate the effectiveness of the model in identifying sarcasm in news headlines.

![image](https://github.com/Aqsa-atif/Deep-Learning-Semester-Project-/assets/88885089/eb836dde-bf25-4102-8efe-4df399f97d53)

## Part b (Text Generation using Irish song lyrics)
Dataset:https://storage.googleapis.com/tensorflow-1-public/course3/irish-lyrics-eof.txt

### Explanation:

The project aims to explore and implement text generation using Bi-Directional Long Short-Term Memory (Bi-LSTM) networks, with a focus on the Irish Songs dataset. The report discusses the challenges of text generation and compares various approaches, emphasizing the advantages of Bi-LSTM in capturing bidirectional context and addressing the vanishing gradient problem. The project includes code snippets for dataset preprocessing, word cloud generation, tokenization, and the implementation of a Bi-LSTM model for text generation. The training process, model components, and optimization techniques, such as the Adam optimizer, are explained. The report concludes by highlighting the robustness of Bi-LSTMs in text generation and suggests potential areas for future research, such as hybrid models. The project also incorporates a user-friendly testing interface using the Gradio library, allowing users to input seed text and generate text predictions from the trained model.

![image](https://github.com/Aqsa-atif/Deep-Learning-Semester-Project-/assets/88885089/78336657-3b0f-44c7-9987-af9a99839901)

